import __init__

import pandas as pd
import os
import json
from utils.helper_functions import get_files, load_mapping_file # Assuming helper_functions is in utils
from db.queries.post.post_bench29 import add_case_metadata
from db.utils.db_utils import get_session

# --- Constants ---
# Directories for test case files
DIR_TREATMENT = "../../data/tests/treatment"
DIR_FINAL_TESTS = "../../data/tests/final"
# Path to the mapping file generated by load_cases.py
MAPPING_FILE_PATH = "../../data/output/mapping_file.jsonl" # Adjust path as needed
TEST_PATTERN = "test_*.csv"
# Exclusion lists for specific files
EXCLUDED_TREATMENT_FILES = []
EXCLUDED_FINAL_TEST_FILES = []

# Flags to exclude entire directories
EXCLUDE_ALL_TREATMENT = False
EXCLUDE_ALL_FINAL_TESTS = True # Defaulting to True as in load_cases.py

VERBOSE = True
# --- Helper Functions ---



# --- Core Logic ---

def load_metadata_file(session, full_path, mapping_data, verbose=False):
    """
    Loads metadata from a single test CSV file into the database.

    Args:
        session: The database session object.
        full_path: The absolute path to the CSV file.
        mapping_data: Dictionary mapping (test_name, original_row_index) to cases_bench_id.
        verbose: Boolean flag for verbose output.
    """
    df = pd.read_csv(full_path)


    file_name = os.path.basename(full_path)
    test_name = file_name.replace(".csv", "")
    print(f"Processing metadata for test: {test_name}")

    for index, row in df.iterrows():
        # Assuming the 'id' column in the CSV corresponds to 'original_row_index' in mapping
        # Note: Removed try-except block, potential errors (KeyError, ValueError) are no longer caught here.
        row_id = int(row['id'])
        mapping_key = (test_name, row_id)

        if not mapping_data.get(mapping_key, None):
            print(f"Warning: No mapping found for {test_name}, row id {row_id}. Skipping metadata.")
            continue

        cases_bench_id = mapping_data[mapping_key]

        ###############  OJOOOO!!!!! THIS IS A MONKEY-PATCH!!!!!!!! ###############
        # Map CSV columns to function arguments based on post_bench29.py
        metadata_dict = {
            "cases_bench_id": cases_bench_id,
            "diagnosted_disease_code": row.get('icd10_diagnostic'),
            "primary_medical_specialty": row.get('icd10_chapter_code'),
            "sub_medical_specialty": row.get('icd10_block_code'),
            "disease_group": row.get('icd10_category_code'),
            "disease_subgroup": row.get('icd10_disease_group_code'),
            "check_exists": True, # Default behavior
            "verbose": verbose
        }

        # Remove keys with None values before passing
        metadata_dict_cleaned = {k: v for k, v in metadata_dict.items() if pd.notna(v)}


        # Add the metadata record

        metadata_id = add_case_metadata(session, **metadata_dict_cleaned)

        # Simplified print condition
        if metadata_id and verbose:
            print(f"  Added metadata for cases_bench_id {cases_bench_id} (CSV row id: {row_id})")


def load_all_metadata(session, all_test_files,
     mapping_data, dir_final_tests,
      dir_treatment=None, verbose=False):
    """
    Loads metadata from multiple specified test files into the database.

    Args:
        session: The database session object.
        all_test_files: A list of filenames (relative to their directories) to process.
        mapping_data: Dictionary mapping (test_name, index) tuples to cases_bench_id.
        dir_final_tests: The directory path for 'final' test files.
        dir_treatment: The directory path for 'treatment' test files. Optional.
        verbose: Boolean flag for verbose output.
    """
    treatment_filenames = [os.path.basename(f) for f in get_files("test_*", dir_treatment, verbose=False)] if dir_treatment else []

    for file in all_test_files:
        if verbose:
        print(f"Processing file for metadata: {file}")
        # Determine the correct directory based on the filename
        is_treatment_file = file in treatment_filenames and dir_treatment is not None
        dir_input = dir_treatment if is_treatment_file else dir_final_tests

        # Check if the determined directory exists
        if not os.path.isdir(dir_input):
             print(f"Warning: Directory not found: {dir_input}. Skipping file {file}.")
             break

        full_path = os.path.join(dir_input, file)

        # Check if the file exists before processing
        if not os.path.isfile(full_path):
            print(f"Warning: File not found: {full_path}. Skipping.")
            continue

        load_metadata_file(session, full_path, mapping_data, verbose=verbose)


def main(
        test_pattern= TEST_PATTERN,
        dir_treatment=DIR_TREATMENT,
        dir_final_tests=DIR_FINAL_TESTS,
        mapping_file_path=MAPPING_FILE_PATH,
        excluded_treatment=None, # Use function default []
        excluded_final=None,     # Use function default []
        exclude_all_treatment=EXCLUDE_ALL_TREATMENT,
        exclude_all_final=EXCLUDE_ALL_FINAL_TESTS,
        verbose=VERBOSE
    ):
    """
    Main function to orchestrate loading test case metadata from CSV files into the database.
    """
    # Handle default empty lists for exclusions
    excluded_treatment_files = excluded_treatment if excluded_treatment is not None else []
    excluded_final_test_files = excluded_final if excluded_final is not None else []

    session = get_session()
    if not session:
        print("Error: Failed to get database session. Exiting.")
        return

    mapping_data = load_mapping_file(mapping_file_path)
    if mapping_data is None:
        print("Error: Failed to load mapping file. Exiting.")
        return
    if not mapping_data:
        print("Warning: Mapping file loaded but is empty.")
        # Decide if processing should continue without mappings

    
    treatment_files = []
    if dir_treatment and not exclude_all_treatment:

        treatment_files = get_files(test_pattern, dir_treatment, verbose=verbose)
        treatment_files = [f for f in treatment_files if f not in excluded_treatment_files]


    final_test_files = []
    if dir_final_tests and not exclude_all_final:

        final_test_files = get_files(test_pattern, dir_final_tests, verbose=verbose)
        final_test_files = [f for f in final_test_files if f not in excluded_final_test_files]

    all_test_files = treatment_files + final_test_files


    if verbose:
        print(f"Found {len(all_test_files)} test files to process for metadata.")
    load_all_metadata(session, all_test_files, mapping_data, dir_final_tests, dir_treatment, verbose)

    if verbose:
    print("Metadata loading process finished.")
    session.close()


if __name__ == "__main__":

    main(
        dir_treatment=DIR_TREATMENT,
        dir_final_tests=DIR_FINAL_TESTS,
        mapping_file_path=MAPPING_FILE_PATH,
        excluded_treatment=EXCLUDED_TREATMENT_FILES,
        excluded_final=EXCLUDED_FINAL_TEST_FILES,
        exclude_all_treatment=EXCLUDE_ALL_TREATMENT,
        exclude_all_final=EXCLUDE_ALL_FINAL_TESTS,
        verbose=VERBOSE
    )