#!/usr/bin/env python3
"""
dxGPT Complete Flow Predicates
Generated by Graph29 Sequential Prompts Framework
Combines all flows: init, retrieve, api call, parser (exactly like dxGPT mermaid)
"""

import sys
import os
from pathlib import Path

# Add the parent directory to sys.path to import the base class
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent / 'generators'))

from generators.predicate_graph import PredicateGraph

class DxGPTCompleteGraph(PredicateGraph):
    def __init__(self):
        super().__init__("dxGPT_complete")
    
    def get_node_categories(self):
        """Return node category mapping for color assignment - exactly like dxGPT mermaid"""
        return {
            # Application Components (Green) - Main Components
            "run_dxGPT_async.py<br/>(Command-line entry)": "application_components",
            "dxGPT_async.py<br/>(Main async workflow)": "application_components",
            "models/dxGPT_models.py": "application_components",
            "prompts/dxGPT_prompts.py": "application_components",
            "parsers/dxGPT_parsers.py": "application_components",
            "serialization/dxgpt_pydantic_models.py": "application_components",
            "queries/dxGPT_queries.py<br/>(Database operations)": "application_components",
            
            # Core Functions (Dark Green)
            "set_settings()": "core_functions",
            "retrieve_and_make_prompts()": "core_functions",
            "process_results()": "core_functions",
            
            # Framework Components (Blue)
            "AsyncModelHandler": "framework_components",
            "process_all_batches()": "framework_components",
            "PromptBuilder": "framework_components",
            
            # Database Tables (Purple)
            "CasesBench<br/>(Input cases)": "database_tables",
            "Models<br/>(LLM configs)": "database_tables",
            "Prompts<br/>(Templates)": "database_tables",
            "LlmDifferentialDiagnosis<br/>(Raw responses)": "database_tables",
            "DifferentialDiagnosis2Rank<br/>(Structured diagnoses)": "database_tables",
            
            # Database Functions (Red)
            "insert_or_fetch_model()<br/>insert_or_fetch_prompt()": "database_functions",
            "get_cases_bench()": "database_functions",
            "add_batch_differential_diagnoses()<br/>in dxGPT_queries": "database_functions",
            "add_differential_diagnosis_to_rank()<br/>in post_bench29": "database_functions",
            
            # Selected Components (Yellow-Brown)
            "Selected dxGPT Prompt<br/>(e.g., StandardDxGPTPrompt)": "selected_components",
            "Selected dxGPT Model<br/>(e.g., LlamaThreeEightBConfig)": "selected_components",
            "Differential Diagnosis Parser<br/>(e.g., parse_top5_xml)": "selected_components",
            "Rank Parser<br/>(e.g., universal_dif_diagnosis_parser)": "selected_components",
            
            # Data Flow Elements (Light Gray)
            "1. inits configuration": "data_flow_elements",
            "model_id": "data_flow_elements",
            "prompt_id": "data_flow_elements",
            "case_bench_id": "data_flow_elements",
            "case_text": "data_flow_elements",
            "Case Model<br/>(Pydantic Schema)": "data_flow_elements",
            "List of Clinical Cases<br/>(Pydantic models)": "data_flow_elements",
            "List of Clinical Cases w/ DDx<br/>(Pydantic Models)": "data_flow_elements",
            "List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)": "data_flow_elements",
            "List of LLM responses<br/>(plain text)": "data_flow_elements",
            "Raw Differential Diagnosis<br/>(Extracted text block)": "data_flow_elements",
            "Differential Diagnosis ID": "data_flow_elements",
            "Rank Position<br/>(Integer)": "data_flow_elements",
            "Disease Name<br/>(String)": "data_flow_elements",
            "Reasoning<br/>(String)": "data_flow_elements",
            
            # Command Arguments (Yellow)
            "--model_alias": "command_arguments",
            "--prompt_alias": "command_arguments",
            "--hospital<br/>--num_samples<br/>--verbose": "command_arguments",
            "--batch_size<br/>--rpm_limit<br/>--min_batch_interval": "command_arguments",
        }
    
    def add_complete_flow(self):
        """Add complete flow predicates exactly like dxGPT mermaid structure"""
        
        triplets = [
            # --- EXECUTION FLOW (exactly like dxGPT mermaid) ---
            
            # Main execution flow
            ("run_dxGPT_async.py<br/>(Command-line entry)", "calls", "dxGPT_async.py<br/>(Main async workflow)"),
            ("dxGPT_async.py<br/>(Main async workflow)", "calls", "set_settings()"),
            ("dxGPT_async.py<br/>(Main async workflow)", "calls", "retrieve_and_make_prompts()"),
            ("dxGPT_async.py<br/>(Main async workflow)", "calls", "process_results()"),
            
            # set_settings output
            ("set_settings()", "produces", "1. inits configuration"),
            
            # config connections
            ("1. inits configuration", "produces", "--model_alias"),
            ("1. inits configuration", "produces", "--prompt_alias"),
            
            # Other function connections
            ("List of Clinical Cases<br/>(Pydantic models)", "sent to", "process_all_batches()"),
            
            # Component connections
            
            # Modified/Added links per request - Prompt flow
            ("--prompt_alias", "sent to", "prompts/dxGPT_prompts.py"),
            ("prompts/dxGPT_prompts.py", "loads", "Selected dxGPT Prompt<br/>(e.g., StandardDxGPTPrompt)"),
            ("PromptBuilder", "extends", "Selected dxGPT Prompt<br/>(e.g., StandardDxGPTPrompt)"),
            ("Selected dxGPT Prompt<br/>(e.g., StandardDxGPTPrompt)", "used by", "process_all_batches()"),
            
            # Modified/Added links per request - Model flow
            ("--model_alias", "sent to", "process_all_batches()"),
            ("AsyncModelHandler", "selects", "models/dxGPT_models.py"),
            ("models/dxGPT_models.py", "loads", "Selected dxGPT Model<br/>(e.g., LlamaThreeEightBConfig)"),
            ("Selected dxGPT Model<br/>(e.g., LlamaThreeEightBConfig)", "produces", "List of LLM responses<br/>(plain text)"),
            
            # Arguments connections
            ("--batch_size<br/>--rpm_limit<br/>--min_batch_interval", "configures", "process_all_batches()"),
            ("retrieve_and_make_prompts()", "uses", "--hospital<br/>--num_samples<br/>--verbose"),
            ("--hospital<br/>--num_samples<br/>--verbose", "sent to", "get_cases_bench()"),
            
            # Database module connections
            ("--model_alias", "sent to", "insert_or_fetch_model()<br/>insert_or_fetch_prompt()"),
            ("--prompt_alias", "sent to", "insert_or_fetch_model()<br/>insert_or_fetch_prompt()"),
            ("insert_or_fetch_model()<br/>insert_or_fetch_prompt()", "queries", "Models<br/>(LLM configs)"),
            ("insert_or_fetch_model()<br/>insert_or_fetch_prompt()", "queries", "Prompts<br/>(Templates)"),
            ("Models<br/>(LLM configs)", "returns", "model_id"),
            ("Prompts<br/>(Templates)", "returns", "prompt_id"),
            
            # CasesBench connections
            ("CasesBench<br/>(Input cases)", "returns", "case_bench_id"),
            ("CasesBench<br/>(Input cases)", "returns", "case_text"),
            ("case_bench_id", "part of", "Case Model<br/>(Pydantic Schema)"),
            ("case_text", "part of", "Case Model<br/>(Pydantic Schema)"),
            ("model_id", "part of", "Case Model<br/>(Pydantic Schema)"),
            ("prompt_id", "part of", "Case Model<br/>(Pydantic Schema)"),
            ("Case Model<br/>(Pydantic Schema)", "generates", "List of Clinical Cases<br/>(Pydantic models)"),
            
            # --- DATA FLOW (exactly like dxGPT mermaid) ---
            
            # retrieve_and_make_prompts() flow
            ("get_cases_bench()", "queries", "CasesBench<br/>(Input cases)"),
            ("serialization/dxgpt_pydantic_models.py", "stored in", "Case Model<br/>(Pydantic Schema)"),
            
            # process_all_batches() flow
            ("process_all_batches()", "calls", "AsyncModelHandler"),
            
            # process_results() flow
            ("process_results()", "uses", "parsers/dxGPT_parsers.py"),
            ("parsers/dxGPT_parsers.py", "contains", "Differential Diagnosis Parser<br/>(e.g., parse_top5_xml)"),
            ("parsers/dxGPT_parsers.py", "contains", "Rank Parser<br/>(e.g., universal_dif_diagnosis_parser)"),
            
            # Parser Data Flow
            ("List of LLM responses<br/>(plain text)", "passed to", "Differential Diagnosis Parser<br/>(e.g., parse_top5_xml)"),
            ("Differential Diagnosis Parser<br/>(e.g., parse_top5_xml)", "produces", "Raw Differential Diagnosis<br/>(Extracted text block)"),
            ("Raw Differential Diagnosis<br/>(Extracted text block)", "input for", "Rank Parser<br/>(e.g., universal_dif_diagnosis_parser)"),
            
            ("List of Clinical Cases<br/>(Pydantic models)", "augmented to", "List of Clinical Cases w/ DDx<br/>(Pydantic Models)"),
            ("Raw Differential Diagnosis<br/>(Extracted text block)", "stored as", "List of Clinical Cases w/ DDx<br/>(Pydantic Models)"),
            ("List of Clinical Cases w/ DDx<br/>(Pydantic Models)", "sent to DB via", "add_batch_differential_diagnoses()<br/>in dxGPT_queries"),
            ("List of Clinical Cases w/ DDx<br/>(Pydantic Models)", "augmented to", "List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)"),
            
            ("Rank Parser<br/>(e.g., universal_dif_diagnosis_parser)", "extracts", "Rank Position<br/>(Integer)"),
            ("Rank Parser<br/>(e.g., universal_dif_diagnosis_parser)", "extracts", "Disease Name<br/>(String)"),
            ("Rank Parser<br/>(e.g., universal_dif_diagnosis_parser)", "extracts", "Reasoning<br/>(String)"),
            
            # Database Insert Flow
            ("dxGPT_async.py<br/>(Main async workflow)", "uses", "queries/dxGPT_queries.py<br/>(Database operations)"),
            ("queries/dxGPT_queries.py<br/>(Database operations)", "calls", "add_batch_differential_diagnoses()<br/>in dxGPT_queries"),
            ("queries/dxGPT_queries.py<br/>(Database operations)", "contains", "add_differential_diagnosis_to_rank()<br/>in post_bench29"),
            ("add_batch_differential_diagnoses()<br/>in dxGPT_queries", "generates", "Differential Diagnosis ID"),
            ("add_batch_differential_diagnoses()<br/>in dxGPT_queries", "writes to", "LlmDifferentialDiagnosis<br/>(Raw responses)"),
            
            ("Rank Position<br/>(Integer)", "stored in", "List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)"),
            ("Disease Name<br/>(String)", "stored in", "List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)"),
            ("Reasoning<br/>(String)", "stored in", "List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)"),
            ("Differential Diagnosis ID", "stored in", "List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)"),
            ("List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)", "sent to DB via", "add_differential_diagnosis_to_rank()<br/>in post_bench29"),
            ("add_differential_diagnosis_to_rank()<br/>in post_bench29", "writes to", "DifferentialDiagnosis2Rank<br/>(Structured diagnoses)"),
        ]
        
        for source, predicate, target in triplets:
            self.add_edge(source, predicate, target)

if __name__ == "__main__":
    # Create and build the graph
    graph = DxGPTCompleteGraph()
    graph.add_complete_flow()
    
    # Print summary
    print(f"Generated {graph.module_name} with {len(graph.nodes)} nodes and {len(graph.edges)} edges")
    
    # Optionally print all triplets for verification
    for source, predicate, target in graph.get_triplets():
        print(f"  ({source}, {predicate}, {target})") 