#!/usr/bin/env python3
"""
Unified Complete Flow Predicates - Improved Version
Generated by Graph29 Sequential Prompts Framework
Combines all three modules with universal tagging and table usage relationships
IMPROVED: Removed all queries/*queries.py intermediate nodes for cleaner architecture
"""

import sys
import os
import json
from pathlib import Path

# Add the current directory to sys.path to import modules
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent / 'generators'))

from generators.predicate_graph import PredicateGraph

def get_all_triplets():
    """Return all triplets from the three modules with universal tagging and usage links - IMPROVED VERSION"""
    
    # dxGPT Module Triplets (56 total) - with universal tagging and queries removed
    dxgpt_triplets = [
        ("run_dxGPT_async.py<br/>(Command-line entry)<br/>(dxGPT)", "calls", "dxGPT_async.py<br/>(Main async workflow)<br/>(dxGPT)"),
        ("dxGPT_async.py<br/>(Main async workflow)<br/>(dxGPT)", "calls", "set_settings()<br/>(dxGPT)"),
        ("dxGPT_async.py<br/>(Main async workflow)<br/>(dxGPT)", "calls", "retrieve_and_make_prompts()<br/>(dxGPT)"),
        ("dxGPT_async.py<br/>(Main async workflow)<br/>(dxGPT)", "calls", "process_results()<br/>(dxGPT)"),
        ("set_settings()<br/>(dxGPT)", "produces", "1. inits configuration<br/>(dxGPT)"),
        ("1. inits configuration<br/>(dxGPT)", "produces", "--model_alias<br/>(dxGPT)"),
        ("1. inits configuration<br/>(dxGPT)", "produces", "--prompt_alias<br/>(dxGPT)"),
        ("List of Clinical Cases<br/>(Pydantic models)<br/>(dxGPT)", "sent to", "process_all_batches()<br/>(dxGPT)"),
        ("--prompt_alias<br/>(dxGPT)", "sent to", "prompts/dxGPT_prompts.py<br/>(dxGPT)"),
        ("prompts/dxGPT_prompts.py<br/>(dxGPT)", "loads", "Selected dxGPT Prompt<br/>(e.g., StandardDxGPTPrompt)<br/>(dxGPT)"),
        ("PromptBuilder<br/>(dxGPT)", "extends", "Selected dxGPT Prompt<br/>(e.g., StandardDxGPTPrompt)<br/>(dxGPT)"),
        ("Selected dxGPT Prompt<br/>(e.g., StandardDxGPTPrompt)<br/>(dxGPT)", "used by", "process_all_batches()<br/>(dxGPT)"),
        ("--model_alias<br/>(dxGPT)", "sent to", "process_all_batches()<br/>(dxGPT)"),
        ("AsyncModelHandler<br/>(dxGPT)", "selects", "models/dxGPT_models.py<br/>(dxGPT)"),
        ("models/dxGPT_models.py<br/>(dxGPT)", "loads", "Selected dxGPT Model<br/>(e.g., LlamaThreeEightBConfig)<br/>(dxGPT)"),
        ("Selected dxGPT Model<br/>(e.g., LlamaThreeEightBConfig)<br/>(dxGPT)", "produces", "List of LLM responses<br/>(plain text)<br/>(dxGPT)"),
        ("--batch_size<br/>--rpm_limit<br/>--min_batch_interval<br/>(dxGPT)", "configures", "process_all_batches()<br/>(dxGPT)"),
        ("retrieve_and_make_prompts()<br/>(dxGPT)", "uses", "--hospital<br/>--num_samples<br/>--verbose<br/>(dxGPT)"),
        ("--hospital<br/>--num_samples<br/>--verbose<br/>(dxGPT)", "sent to", "get_cases_bench()<br/>(dxGPT)"),
        ("--model_alias<br/>(dxGPT)", "sent to", "insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(dxGPT)"),
        ("--prompt_alias<br/>(dxGPT)", "sent to", "insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(dxGPT)"),
        ("insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(dxGPT)", "queries", "Models<br/>(LLM configs)<br/>(dxGPT)"),
        ("insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(dxGPT)", "queries", "Prompts<br/>(Templates)<br/>(dxGPT)"),
        ("Models<br/>(LLM configs)<br/>(dxGPT)", "returns", "model_id<br/>(dxGPT)"),
        ("Prompts<br/>(Templates)<br/>(dxGPT)", "returns", "prompt_id<br/>(dxGPT)"),
        ("CasesBench<br/>(Input cases)<br/>(dxGPT)", "returns", "case_bench_id<br/>(dxGPT)"),
        ("CasesBench<br/>(Input cases)<br/>(dxGPT)", "returns", "case_text<br/>(dxGPT)"),
        ("case_bench_id<br/>(dxGPT)", "part of", "Case Model<br/>(Pydantic Schema)<br/>(dxGPT)"),
        ("case_text<br/>(dxGPT)", "part of", "Case Model<br/>(Pydantic Schema)<br/>(dxGPT)"),
        ("model_id<br/>(dxGPT)", "part of", "Case Model<br/>(Pydantic Schema)<br/>(dxGPT)"),
        ("prompt_id<br/>(dxGPT)", "part of", "Case Model<br/>(Pydantic Schema)<br/>(dxGPT)"),
        ("Case Model<br/>(Pydantic Schema)<br/>(dxGPT)", "generates", "List of Clinical Cases<br/>(Pydantic models)<br/>(dxGPT)"),
        ("get_cases_bench()<br/>(dxGPT)", "queries", "CasesBench<br/>(Input cases)<br/>(dxGPT)"),
        ("serialization/dxgpt_pydantic_models.py<br/>(dxGPT)", "stored in", "Case Model<br/>(Pydantic Schema)<br/>(dxGPT)"),
        ("process_all_batches()<br/>(dxGPT)", "calls", "AsyncModelHandler<br/>(dxGPT)"),
        ("process_results()<br/>(dxGPT)", "uses", "parsers/dxGPT_parsers.py<br/>(dxGPT)"),
        ("parsers/dxGPT_parsers.py<br/>(dxGPT)", "contains", "Differential Diagnosis Parser<br/>(e.g., parse_top5_xml)<br/>(dxGPT)"),
        ("parsers/dxGPT_parsers.py<br/>(dxGPT)", "contains", "Rank Parser<br/>(e.g., universal_dif_diagnosis_parser)<br/>(dxGPT)"),
        ("List of LLM responses<br/>(plain text)<br/>(dxGPT)", "passed to", "Differential Diagnosis Parser<br/>(e.g., parse_top5_xml)<br/>(dxGPT)"),
        ("Differential Diagnosis Parser<br/>(e.g., parse_top5_xml)<br/>(dxGPT)", "produces", "Raw Differential Diagnosis<br/>(Extracted text block)<br/>(dxGPT)"),
        ("Raw Differential Diagnosis<br/>(Extracted text block)<br/>(dxGPT)", "input for", "Rank Parser<br/>(e.g., universal_dif_diagnosis_parser)<br/>(dxGPT)"),
        ("List of Clinical Cases<br/>(Pydantic models)<br/>(dxGPT)", "augmented to", "List of Clinical Cases w/ DDx<br/>(Pydantic Models)<br/>(dxGPT)"),
        ("Raw Differential Diagnosis<br/>(Extracted text block)<br/>(dxGPT)", "stored as", "List of Clinical Cases w/ DDx<br/>(Pydantic Models)<br/>(dxGPT)"),
        ("List of Clinical Cases w/ DDx<br/>(Pydantic Models)<br/>(dxGPT)", "sent to DB via", "add_batch_differential_diagnoses()<br/>in dxGPT_queries<br/>(dxGPT)"),
        ("List of Clinical Cases w/ DDx<br/>(Pydantic Models)<br/>(dxGPT)", "augmented to", "List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)<br/>(dxGPT)"),
        ("Rank Parser<br/>(e.g., universal_dif_diagnosis_parser)<br/>(dxGPT)", "extracts", "Rank Position<br/>(Integer)<br/>(dxGPT)"),
        ("Rank Parser<br/>(e.g., universal_dif_diagnosis_parser)<br/>(dxGPT)", "extracts", "Disease Name<br/>(String)<br/>(dxGPT)"),
        ("Rank Parser<br/>(e.g., universal_dif_diagnosis_parser)<br/>(dxGPT)", "extracts", "Reasoning<br/>(String)<br/>(dxGPT)"),
        # IMPROVED: Direct connection from main module to database functions, bypassing queries module
        ("dxGPT_async.py<br/>(Main async workflow)<br/>(dxGPT)", "calls", "add_batch_differential_diagnoses()<br/>in dxGPT_queries<br/>(dxGPT)"),
        ("dxGPT_async.py<br/>(Main async workflow)<br/>(dxGPT)", "calls", "add_differential_diagnosis_to_rank()<br/>in post_bench29<br/>(dxGPT)"),
        ("add_batch_differential_diagnoses()<br/>in dxGPT_queries<br/>(dxGPT)", "generates", "Differential Diagnosis ID<br/>(dxGPT)"),
        ("add_batch_differential_diagnoses()<br/>in dxGPT_queries<br/>(dxGPT)", "writes to", "LlmDifferentialDiagnosis<br/>(Raw responses)<br/>(dxGPT)"),
        ("Rank Position<br/>(Integer)<br/>(dxGPT)", "stored in", "List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)<br/>(dxGPT)"),
        ("Disease Name<br/>(String)<br/>(dxGPT)", "stored in", "List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)<br/>(dxGPT)"),
        ("Reasoning<br/>(String)<br/>(dxGPT)", "stored in", "List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)<br/>(dxGPT)"),
        ("Differential Diagnosis ID<br/>(dxGPT)", "stored in", "List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)<br/>(dxGPT)"),
        ("List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)<br/>(dxGPT)", "sent to DB via", "add_differential_diagnosis_to_rank()<br/>in post_bench29<br/>(dxGPT)"),
        ("add_differential_diagnosis_to_rank()<br/>in post_bench29<br/>(dxGPT)", "writes to", "DifferentialDiagnosis2Rank<br/>(Structured diagnoses)<br/>(dxGPT)"),
    ]
    
    # Semantic Judge Module Triplets (52 total) - with universal tagging and queries removed
    semantic_triplets = [
        ("run_judge_semantic_async.py<br/>(Command-line entry)<br/>(Semantic Judge)", "calls", "judge_semantic_async.py<br/>(Main async workflow)<br/>(Semantic Judge)"),
        ("judge_semantic_async.py<br/>(Main async workflow)<br/>(Semantic Judge)", "calls", "set_settings()<br/>(Semantic Judge)"),
        ("judge_semantic_async.py<br/>(Main async workflow)<br/>(Semantic Judge)", "calls", "retrieve_and_make_prompts()<br/>(Semantic Judge)"),
        ("judge_semantic_async.py<br/>(Main async workflow)<br/>(Semantic Judge)", "calls", "process_results()<br/>(Semantic Judge)"),
        ("set_settings()<br/>(Semantic Judge)", "produces", "1. inits configuration<br/>(Semantic Judge)"),
        ("1. inits configuration<br/>(Semantic Judge)", "produces", "--model_alias<br/>(Semantic Judge)"),
        ("1. inits configuration<br/>(Semantic Judge)", "produces", "--prompt_alias<br/>(Semantic Judge)"),
        ("(Judgment Cases Pydantic Schema)<br/>(Semantic Judge)", "sent to", "process_all_batches()<br/>(Semantic Judge)"),
        ("--prompt_alias<br/>(Semantic Judge)", "sent to", "prompts/judge_semantic_prompts.py<br/>(Semantic Judge)"),
        ("prompts/judge_semantic_prompts.py<br/>(Semantic Judge)", "loads", "Selected Semantic Judge Prompt<br/>(e.g., StandardSemanticJudgePrompt)<br/>(Semantic Judge)"),
        ("PromptBuilder<br/>(Semantic Judge)", "extends", "Selected Semantic Judge Prompt<br/>(e.g., StandardSemanticJudgePrompt)<br/>(Semantic Judge)"),
        ("Selected Semantic Judge Prompt<br/>(e.g., StandardSemanticJudgePrompt)<br/>(Semantic Judge)", "used by", "process_all_batches()<br/>(Semantic Judge)"),
        ("--model_alias<br/>(Semantic Judge)", "sent to", "process_all_batches()<br/>(Semantic Judge)"),
        ("AsyncModelHandler<br/>(Semantic Judge)", "selects", "models/judge_semantic_models.py<br/>(Semantic Judge)"),
        ("models/judge_semantic_models.py<br/>(Semantic Judge)", "loads", "Selected Semantic Judge Model<br/>(e.g., LlamaThreeEightBConfig)<br/>(Semantic Judge)"),
        ("Selected Semantic Judge Model<br/>(e.g., LlamaThreeEightBConfig)<br/>(Semantic Judge)", "produces", "List of Semantic Judgments<br/>(plain text)<br/>(Semantic Judge)"),
        ("--batch_size<br/>--rpm_limit<br/>--min_batch_interval<br/>(Semantic Judge)", "configures", "process_all_batches()<br/>(Semantic Judge)"),
        ("retrieve_and_make_prompts()<br/>(Semantic Judge)", "uses", "--differential_diagnosis_model<br/>--test_name<br/>--max_diagnoses<br/>(Semantic Judge)"),
        ("--differential_diagnosis_model<br/>--test_name<br/>--max_diagnoses<br/>(Semantic Judge)", "sent to", "get_cases()<br/>get_case_to_golden_diagnosis_mapping()<br/>get_model_names_from_differential_diagnosis()<br/>get_ranks_for_hospital_and_model_id()<br/>get_model_id_from_name()<br/>create_nested_diagnosis_dict()<br/>(Semantic Judge)"),
        ("--model_alias<br/>(Semantic Judge)", "sent to", "insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(Semantic Judge)"),
        ("--prompt_alias<br/>(Semantic Judge)", "sent to", "insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(Semantic Judge)"),
        ("insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(Semantic Judge)", "queries", "Models<br/>(LLM configs)<br/>(Semantic Judge)"),
        ("insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(Semantic Judge)", "queries", "Prompts<br/>(Templates)<br/>(Semantic Judge)"),
        ("Models<br/>(LLM configs)<br/>(Semantic Judge)", "returns", "model_id<br/>(Semantic Judge)"),
        ("Prompts<br/>(Templates)<br/>(Semantic Judge)", "returns", "prompt_id<br/>(Semantic Judge)"),
        ("CasesBench<br/>(Input cases)<br/>(Semantic Judge)", "returns", "case_bench_id<br/>(Semantic Judge)"),
        ("CasesBench<br/>(Input cases)<br/>(Semantic Judge)", "returns", "case_text<br/>(Semantic Judge)"),
        ("case_bench_id<br/>(Semantic Judge)", "part of", "Case Model<br/>(Pydantic Schema)<br/>(Semantic Judge)"),
        ("case_text<br/>(Semantic Judge)", "part of", "Case Model<br/>(Pydantic Schema)<br/>(Semantic Judge)"),
        ("model_id<br/>(Semantic Judge)", "part of", "Case Model<br/>(Pydantic Schema)<br/>(Semantic Judge)"),
        ("prompt_id<br/>(Semantic Judge)", "part of", "Case Model<br/>(Pydantic Schema)<br/>(Semantic Judge)"),
        ("Case Model<br/>(Pydantic Schema)<br/>(Semantic Judge)", "generates", "List of Clinical Cases<br/>(Pydantic models)<br/>(Semantic Judge)"),
        ("get_cases()<br/>get_case_to_golden_diagnosis_mapping()<br/>get_model_names_from_differential_diagnosis()<br/>get_ranks_for_hospital_and_model_id()<br/>get_model_id_from_name()<br/>create_nested_diagnosis_dict()<br/>(Semantic Judge)", "queries", "CasesBench<br/>(Input cases)<br/>(Semantic Judge)"),
        ("get_cases()<br/>get_case_to_golden_diagnosis_mapping()<br/>get_model_names_from_differential_diagnosis()<br/>get_ranks_for_hospital_and_model_id()<br/>get_model_id_from_name()<br/>create_nested_diagnosis_dict()<br/>(Semantic Judge)", "queries", "GoldenDiagnoses<br/>(Ground truth)<br/>(Semantic Judge)"),
        ("get_cases()<br/>get_case_to_golden_diagnosis_mapping()<br/>get_model_names_from_differential_diagnosis()<br/>get_ranks_for_hospital_and_model_id()<br/>get_model_id_from_name()<br/>create_nested_diagnosis_dict()<br/>(Semantic Judge)", "queries", "DifferentialDiagnosis2Rank<br/>(Ranked diagnoses)<br/>(Semantic Judge)"),
        ("serialization/judge_semantic_pydantic_models.py<br/>(Semantic Judge)", "stored in", "Case Model<br/>(Pydantic Schema)<br/>(Semantic Judge)"),
        ("Case Model<br/>(Pydantic Schema)<br/>(Semantic Judge)", "generates", "(Judgment Cases Pydantic Schema)<br/>(Semantic Judge)"),
        ("process_all_batches()<br/>(Semantic Judge)", "calls", "AsyncModelHandler<br/>(Semantic Judge)"),
        ("process_results()<br/>(Semantic Judge)", "uses", "parsers/judge_semantic_parser.py<br/>(Semantic Judge)"),
        ("parsers/judge_semantic_parser.py<br/>(Semantic Judge)", "contains", "Semantic Judgment Parser<br/>(e.g., parse_judged_semantic)<br/>(Semantic Judge)"),
        ("List of Semantic Judgments<br/>(plain text)<br/>(Semantic Judge)", "passed to", "Semantic Judgment Parser<br/>(e.g., parse_judged_semantic)<br/>(Semantic Judge)"),
        ("Semantic Judgment Parser<br/>(e.g., parse_judged_semantic)<br/>(Semantic Judge)", "produces", "Raw Semantic Judgment<br/>(JSON response)<br/>(Semantic Judge)"),
        ("List of Clinical Cases<br/>(Pydantic models)<br/>(Semantic Judge)", "augmented to", "List of Judgment Cases w/ Semantic Results<br/>(Pydantic Models)<br/>(Semantic Judge)"),
        ("Raw Semantic Judgment<br/>(JSON response)<br/>(Semantic Judge)", "stored as", "List of Judgment Cases w/ Semantic Results<br/>(Pydantic Models)<br/>(Semantic Judge)"),
        ("List of Judgment Cases w/ Semantic Results<br/>(Pydantic Models)<br/>(Semantic Judge)", "sent to DB via", "add_semantic_results_to_db()<br/>in semantic_queries<br/>(Semantic Judge)"),
        ("Semantic Judgment Parser<br/>(e.g., parse_judged_semantic)<br/>(Semantic Judge)", "extracts", "differential_diagnosis_semantic_relationship_id<br/>(Integer)<br/>(Semantic Judge)"),
        ("Semantic Judgment Parser<br/>(e.g., parse_judged_semantic)<br/>(Semantic Judge)", "extracts", "cases_bench_id<br/>(Integer)<br/>(Semantic Judge)"),
        ("Semantic Judgment Parser<br/>(e.g., parse_judged_semantic)<br/>(Semantic Judge)", "extracts", "rank_id<br/>(Integer)<br/>(Semantic Judge)"),
        # IMPROVED: Direct connection from main module to database function, bypassing queries module
        ("judge_semantic_async.py<br/>(Main async workflow)<br/>(Semantic Judge)", "calls", "add_semantic_results_to_db()<br/>in semantic_queries<br/>(Semantic Judge)"),
        ("add_semantic_results_to_db()<br/>in semantic_queries<br/>(Semantic Judge)", "writes to", "DifferentialDiagnosis2SemanticRelationship<br/>(Semantic judgments)<br/>(Semantic Judge)"),
        ("differential_diagnosis_semantic_relationship_id<br/>(Integer)<br/>(Semantic Judge)", "stored in", "List of Judgment Cases w/ Semantic Results<br/>(Pydantic Models)<br/>(Semantic Judge)"),
        ("cases_bench_id<br/>(Integer)<br/>(Semantic Judge)", "stored in", "List of Judgment Cases w/ Semantic Results<br/>(Pydantic Models)<br/>(Semantic Judge)"),
        ("rank_id<br/>(Integer)<br/>(Semantic Judge)", "stored in", "List of Judgment Cases w/ Semantic Results<br/>(Pydantic Models)<br/>(Semantic Judge)"),
    ]
    
    # Severity Judge Module Triplets (52 total) - with universal tagging and queries removed
    severity_triplets = [
        ("run_judge_severity_async.py<br/>(Command-line entry)<br/>(Severity Judge)", "calls", "judge_severity_async.py<br/>(Main async workflow)<br/>(Severity Judge)"),
        ("judge_severity_async.py<br/>(Main async workflow)<br/>(Severity Judge)", "calls", "set_settings()<br/>(Severity Judge)"),
        ("judge_severity_async.py<br/>(Main async workflow)<br/>(Severity Judge)", "calls", "retrieve_and_make_prompts()<br/>(Severity Judge)"),
        ("judge_severity_async.py<br/>(Main async workflow)<br/>(Severity Judge)", "calls", "process_results()<br/>(Severity Judge)"),
        ("set_settings()<br/>(Severity Judge)", "produces", "1. inits configuration<br/>(Severity Judge)"),
        ("1. inits configuration<br/>(Severity Judge)", "produces", "--model_alias<br/>(Severity Judge)"),
        ("1. inits configuration<br/>(Severity Judge)", "produces", "--prompt_alias<br/>(Severity Judge)"),
        ("(Judgment Cases Pydantic Schema)<br/>(Severity Judge)", "sent to", "process_all_batches()<br/>(Severity Judge)"),
        ("--prompt_alias<br/>(Severity Judge)", "sent to", "prompts/judge_severity_prompts.py<br/>(Severity Judge)"),
        ("prompts/judge_severity_prompts.py<br/>(Severity Judge)", "loads", "Selected Severity Judge Prompt<br/>(e.g., StandardSeverityJudgePrompt)<br/>(Severity Judge)"),
        ("PromptBuilder<br/>(Severity Judge)", "extends", "Selected Severity Judge Prompt<br/>(e.g., StandardSeverityJudgePrompt)<br/>(Severity Judge)"),
        ("Selected Severity Judge Prompt<br/>(e.g., StandardSeverityJudgePrompt)<br/>(Severity Judge)", "used by", "process_all_batches()<br/>(Severity Judge)"),
        ("--model_alias<br/>(Severity Judge)", "sent to", "process_all_batches()<br/>(Severity Judge)"),
        ("AsyncModelHandler<br/>(Severity Judge)", "selects", "models/judge_severity_models.py<br/>(Severity Judge)"),
        ("models/judge_severity_models.py<br/>(Severity Judge)", "loads", "Selected Severity Judge Model<br/>(e.g., LlamaThreeEightBConfig)<br/>(Severity Judge)"),
        ("Selected Severity Judge Model<br/>(e.g., LlamaThreeEightBConfig)<br/>(Severity Judge)", "produces", "List of Severity Assessments<br/>(plain text)<br/>(Severity Judge)"),
        ("--batch_size<br/>--rpm_limit<br/>--min_batch_interval<br/>(Severity Judge)", "configures", "process_all_batches()<br/>(Severity Judge)"),
        ("retrieve_and_make_prompts()<br/>(Severity Judge)", "uses", "--differential_diagnosis_model<br/>--test_name<br/>--max_diagnoses<br/>(Severity Judge)"),
        ("--differential_diagnosis_model<br/>--test_name<br/>--max_diagnoses<br/>(Severity Judge)", "sent to", "get_cases()<br/>get_case_to_golden_diagnosis_mapping()<br/>get_model_names_from_differential_diagnosis()<br/>get_ranks_for_hospital_and_model_id()<br/>get_model_id_from_name()<br/>create_nested_diagnosis_dict()<br/>(Severity Judge)"),
        ("--model_alias<br/>(Severity Judge)", "sent to", "insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(Severity Judge)"),
        ("--prompt_alias<br/>(Severity Judge)", "sent to", "insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(Severity Judge)"),
        ("insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(Severity Judge)", "queries", "Models<br/>(LLM configs)<br/>(Severity Judge)"),
        ("insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(Severity Judge)", "queries", "Prompts<br/>(Templates)<br/>(Severity Judge)"),
        ("Models<br/>(LLM configs)<br/>(Severity Judge)", "returns", "model_id<br/>(Severity Judge)"),
        ("Prompts<br/>(Templates)<br/>(Severity Judge)", "returns", "prompt_id<br/>(Severity Judge)"),
        ("CasesBench<br/>(Input cases)<br/>(Severity Judge)", "returns", "case_bench_id<br/>(Severity Judge)"),
        ("CasesBench<br/>(Input cases)<br/>(Severity Judge)", "returns", "case_text<br/>(Severity Judge)"),
        ("case_bench_id<br/>(Severity Judge)", "part of", "Case Model<br/>(Pydantic Schema)<br/>(Severity Judge)"),
        ("case_text<br/>(Severity Judge)", "part of", "Case Model<br/>(Pydantic Schema)<br/>(Severity Judge)"),
        ("model_id<br/>(Severity Judge)", "part of", "Case Model<br/>(Pydantic Schema)<br/>(Severity Judge)"),
        ("prompt_id<br/>(Severity Judge)", "part of", "Case Model<br/>(Pydantic Schema)<br/>(Severity Judge)"),
        ("Case Model<br/>(Pydantic Schema)<br/>(Severity Judge)", "generates", "List of Clinical Cases<br/>(Pydantic models)<br/>(Severity Judge)"),
        ("get_cases()<br/>get_case_to_golden_diagnosis_mapping()<br/>get_model_names_from_differential_diagnosis()<br/>get_ranks_for_hospital_and_model_id()<br/>get_model_id_from_name()<br/>create_nested_diagnosis_dict()<br/>(Severity Judge)", "queries", "CasesBench<br/>(Input cases)<br/>(Severity Judge)"),
        ("get_cases()<br/>get_case_to_golden_diagnosis_mapping()<br/>get_model_names_from_differential_diagnosis()<br/>get_ranks_for_hospital_and_model_id()<br/>get_model_id_from_name()<br/>create_nested_diagnosis_dict()<br/>(Severity Judge)", "queries", "GoldenDiagnoses<br/>(Ground truth)<br/>(Severity Judge)"),
        ("get_cases()<br/>get_case_to_golden_diagnosis_mapping()<br/>get_model_names_from_differential_diagnosis()<br/>get_ranks_for_hospital_and_model_id()<br/>get_model_id_from_name()<br/>create_nested_diagnosis_dict()<br/>(Severity Judge)", "queries", "DifferentialDiagnosis2Rank<br/>(Ranked diagnoses)<br/>(Severity Judge)"),
        ("serialization/judge_severity_pydantic_models.py<br/>(Severity Judge)", "stored in", "Case Model<br/>(Pydantic Schema)<br/>(Severity Judge)"),
        ("Case Model<br/>(Pydantic Schema)<br/>(Severity Judge)", "generates", "(Judgment Cases Pydantic Schema)<br/>(Severity Judge)"),
        ("process_all_batches()<br/>(Severity Judge)", "calls", "AsyncModelHandler<br/>(Severity Judge)"),
        ("process_results()<br/>(Severity Judge)", "uses", "parsers/judge_severity_parser.py<br/>(Severity Judge)"),
        ("parsers/judge_severity_parser.py<br/>(Severity Judge)", "contains", "Severity Assessment Parser<br/>(e.g., parse_judged_severity)<br/>(Severity Judge)"),
        ("List of Severity Assessments<br/>(plain text)<br/>(Severity Judge)", "passed to", "Severity Assessment Parser<br/>(e.g., parse_judged_severity)<br/>(Severity Judge)"),
        ("Severity Assessment Parser<br/>(e.g., parse_judged_severity)<br/>(Severity Judge)", "produces", "Raw Severity Assessment<br/>(JSON response)<br/>(Severity Judge)"),
        ("List of Clinical Cases<br/>(Pydantic models)<br/>(Severity Judge)", "augmented to", "List of Judgment Cases w/ Severity Results<br/>(Pydantic Models)<br/>(Severity Judge)"),
        ("Raw Severity Assessment<br/>(JSON response)<br/>(Severity Judge)", "stored as", "List of Judgment Cases w/ Severity Results<br/>(Pydantic Models)<br/>(Severity Judge)"),
        ("List of Judgment Cases w/ Severity Results<br/>(Pydantic Models)<br/>(Severity Judge)", "sent to DB via", "add_severity_results_to_db()<br/>in severity_queries<br/>(Severity Judge)"),
        ("Severity Assessment Parser<br/>(e.g., parse_judged_severity)<br/>(Severity Judge)", "extracts", "differential_diagnosis_severity_assessment_id<br/>(Integer)<br/>(Severity Judge)"),
        ("Severity Assessment Parser<br/>(e.g., parse_judged_severity)<br/>(Severity Judge)", "extracts", "cases_bench_id<br/>(Integer)<br/>(Severity Judge)"),
        ("Severity Assessment Parser<br/>(e.g., parse_judged_severity)<br/>(Severity Judge)", "extracts", "rank_id<br/>(Integer)<br/>(Severity Judge)"),
        # IMPROVED: Direct connection from main module to database function, bypassing queries module
        ("judge_severity_async.py<br/>(Main async workflow)<br/>(Severity Judge)", "calls", "add_severity_results_to_db()<br/>in severity_queries<br/>(Severity Judge)"),
        ("add_severity_results_to_db()<br/>in severity_queries<br/>(Severity Judge)", "writes to", "DifferentialDiagnosis2SeverityAssessment<br/>(Severity assessments)<br/>(Severity Judge)"),
        ("differential_diagnosis_severity_assessment_id<br/>(Integer)<br/>(Severity Judge)", "stored in", "List of Judgment Cases w/ Severity Results<br/>(Pydantic Models)<br/>(Severity Judge)"),
        ("cases_bench_id<br/>(Integer)<br/>(Severity Judge)", "stored in", "List of Judgment Cases w/ Severity Results<br/>(Pydantic Models)<br/>(Severity Judge)"),
        ("rank_id<br/>(Integer)<br/>(Severity Judge)", "stored in", "List of Judgment Cases w/ Severity Results<br/>(Pydantic Models)<br/>(Severity Judge)"),
    ]
    
    # Usage Links - The 2 specific links as requested
    usage_links = [
        ("DifferentialDiagnosis2Rank<br/>(Structured diagnoses)<br/>(dxGPT)", "used by", "judge_semantic_async.py<br/>(Main async workflow)<br/>(Semantic Judge)"),
        ("DifferentialDiagnosis2Rank<br/>(Structured diagnoses)<br/>(dxGPT)", "used by", "judge_severity_async.py<br/>(Main async workflow)<br/>(Severity Judge)"),
    ]
    
    # Combine all triplets
    all_triplets = dxgpt_triplets + semantic_triplets + severity_triplets + usage_links
    return all_triplets

def get_node_categories():
    """Return node category mapping for color assignment - IMPROVED VERSION (without queries modules)"""
    categories = {}
    
    # Application Components (Green) - Main Components (REMOVED queries modules)
    app_components = [
        "run_dxGPT_async.py<br/>(Command-line entry)<br/>(dxGPT)",
        "dxGPT_async.py<br/>(Main async workflow)<br/>(dxGPT)",
        "models/dxGPT_models.py<br/>(dxGPT)",
        "prompts/dxGPT_prompts.py<br/>(dxGPT)",
        "parsers/dxGPT_parsers.py<br/>(dxGPT)",
        "serialization/dxgpt_pydantic_models.py<br/>(dxGPT)",
        "run_judge_semantic_async.py<br/>(Command-line entry)<br/>(Semantic Judge)",
        "judge_semantic_async.py<br/>(Main async workflow)<br/>(Semantic Judge)",
        "models/judge_semantic_models.py<br/>(Semantic Judge)",
        "prompts/judge_semantic_prompts.py<br/>(Semantic Judge)",
        "parsers/judge_semantic_parser.py<br/>(Semantic Judge)",
        "serialization/judge_semantic_pydantic_models.py<br/>(Semantic Judge)",
        "run_judge_severity_async.py<br/>(Command-line entry)<br/>(Severity Judge)",
        "judge_severity_async.py<br/>(Main async workflow)<br/>(Severity Judge)",
        "models/judge_severity_models.py<br/>(Severity Judge)",
        "prompts/judge_severity_prompts.py<br/>(Severity Judge)",
        "parsers/judge_severity_parser.py<br/>(Severity Judge)",
        "serialization/judge_severity_pydantic_models.py<br/>(Severity Judge)",
    ]
    
    # Core Functions (Dark Green)
    core_functions = [
        "set_settings()<br/>(dxGPT)",
        "retrieve_and_make_prompts()<br/>(dxGPT)",
        "process_results()<br/>(dxGPT)",
        "set_settings()<br/>(Semantic Judge)",
        "retrieve_and_make_prompts()<br/>(Semantic Judge)",
        "process_results()<br/>(Semantic Judge)",
        "set_settings()<br/>(Severity Judge)",
        "retrieve_and_make_prompts()<br/>(Severity Judge)",
        "process_results()<br/>(Severity Judge)",
    ]
    
    # Framework Components (Blue)
    framework_components = [
        "AsyncModelHandler<br/>(dxGPT)",
        "process_all_batches()<br/>(dxGPT)",
        "PromptBuilder<br/>(dxGPT)",
        "AsyncModelHandler<br/>(Semantic Judge)",
        "process_all_batches()<br/>(Semantic Judge)",
        "PromptBuilder<br/>(Semantic Judge)",
        "AsyncModelHandler<br/>(Severity Judge)",
        "process_all_batches()<br/>(Severity Judge)",
        "PromptBuilder<br/>(Severity Judge)",
    ]
    
    # Database Tables (Purple)
    database_tables = [
        "CasesBench<br/>(Input cases)<br/>(dxGPT)",
        "Models<br/>(LLM configs)<br/>(dxGPT)",
        "Prompts<br/>(Templates)<br/>(dxGPT)",
        "LlmDifferentialDiagnosis<br/>(Raw responses)<br/>(dxGPT)",
        "DifferentialDiagnosis2Rank<br/>(Structured diagnoses)<br/>(dxGPT)",
        "CasesBench<br/>(Input cases)<br/>(Semantic Judge)",
        "Models<br/>(LLM configs)<br/>(Semantic Judge)",
        "Prompts<br/>(Templates)<br/>(Semantic Judge)",
        "GoldenDiagnoses<br/>(Ground truth)<br/>(Semantic Judge)",
        "DifferentialDiagnosis2Rank<br/>(Ranked diagnoses)<br/>(Semantic Judge)",
        "DifferentialDiagnosis2SemanticRelationship<br/>(Semantic judgments)<br/>(Semantic Judge)",
        "CasesBench<br/>(Input cases)<br/>(Severity Judge)",
        "Models<br/>(LLM configs)<br/>(Severity Judge)",
        "Prompts<br/>(Templates)<br/>(Severity Judge)",
        "GoldenDiagnoses<br/>(Ground truth)<br/>(Severity Judge)",
        "DifferentialDiagnosis2Rank<br/>(Ranked diagnoses)<br/>(Severity Judge)",
        "DifferentialDiagnosis2SeverityAssessment<br/>(Severity assessments)<br/>(Severity Judge)",
    ]
    
    # Database Functions (Red)
    database_functions = [
        "insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(dxGPT)",
        "get_cases_bench()<br/>(dxGPT)",
        "add_batch_differential_diagnoses()<br/>in dxGPT_queries<br/>(dxGPT)",
        "add_differential_diagnosis_to_rank()<br/>in post_bench29<br/>(dxGPT)",
        "insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(Semantic Judge)",
        "get_cases()<br/>get_case_to_golden_diagnosis_mapping()<br/>get_model_names_from_differential_diagnosis()<br/>get_ranks_for_hospital_and_model_id()<br/>get_model_id_from_name()<br/>create_nested_diagnosis_dict()<br/>(Semantic Judge)",
        "add_semantic_results_to_db()<br/>in semantic_queries<br/>(Semantic Judge)",
        "insert_or_fetch_model()<br/>insert_or_fetch_prompt()<br/>(Severity Judge)",
        "get_cases()<br/>get_case_to_golden_diagnosis_mapping()<br/>get_model_names_from_differential_diagnosis()<br/>get_ranks_for_hospital_and_model_id()<br/>get_model_id_from_name()<br/>create_nested_diagnosis_dict()<br/>(Severity Judge)",
        "add_severity_results_to_db()<br/>in severity_queries<br/>(Severity Judge)",
    ]
    
    # Selected Components (Yellow-Brown)
    selected_components = [
        "Selected dxGPT Prompt<br/>(e.g., StandardDxGPTPrompt)<br/>(dxGPT)",
        "Selected dxGPT Model<br/>(e.g., LlamaThreeEightBConfig)<br/>(dxGPT)",
        "Differential Diagnosis Parser<br/>(e.g., parse_top5_xml)<br/>(dxGPT)",
        "Rank Parser<br/>(e.g., universal_dif_diagnosis_parser)<br/>(dxGPT)",
        "Selected Semantic Judge Prompt<br/>(e.g., StandardSemanticJudgePrompt)<br/>(Semantic Judge)",
        "Selected Semantic Judge Model<br/>(e.g., LlamaThreeEightBConfig)<br/>(Semantic Judge)",
        "Semantic Judgment Parser<br/>(e.g., parse_judged_semantic)<br/>(Semantic Judge)",
        "Selected Severity Judge Prompt<br/>(e.g., StandardSeverityJudgePrompt)<br/>(Severity Judge)",
        "Selected Severity Judge Model<br/>(e.g., LlamaThreeEightBConfig)<br/>(Severity Judge)",
        "Severity Assessment Parser<br/>(e.g., parse_judged_severity)<br/>(Severity Judge)",
    ]
    
    # Command Arguments (Yellow)
    command_arguments = [
        "--model_alias<br/>(dxGPT)",
        "--prompt_alias<br/>(dxGPT)",
        "--hospital<br/>--num_samples<br/>--verbose<br/>(dxGPT)",
        "--batch_size<br/>--rpm_limit<br/>--min_batch_interval<br/>(dxGPT)",
        "--model_alias<br/>(Semantic Judge)",
        "--prompt_alias<br/>(Semantic Judge)",
        "--differential_diagnosis_model<br/>--test_name<br/>--max_diagnoses<br/>(Semantic Judge)",
        "--batch_size<br/>--rpm_limit<br/>--min_batch_interval<br/>(Semantic Judge)",
        "--model_alias<br/>(Severity Judge)",
        "--prompt_alias<br/>(Severity Judge)",
        "--differential_diagnosis_model<br/>--test_name<br/>--max_diagnoses<br/>(Severity Judge)",
        "--batch_size<br/>--rpm_limit<br/>--min_batch_interval<br/>(Severity Judge)",
    ]
    
    # Data Flow Elements (Light Gray) - All remaining nodes
    data_flow_elements = [
        "1. inits configuration<br/>(dxGPT)",
        "model_id<br/>(dxGPT)",
        "prompt_id<br/>(dxGPT)",
        "case_bench_id<br/>(dxGPT)",
        "case_text<br/>(dxGPT)",
        "Case Model<br/>(Pydantic Schema)<br/>(dxGPT)",
        "List of Clinical Cases<br/>(Pydantic models)<br/>(dxGPT)",
        "List of Clinical Cases w/ DDx<br/>(Pydantic Models)<br/>(dxGPT)",
        "List of Clinical Cases w/ DDx and Ranks<br/>(Pydantic Models)<br/>(dxGPT)",
        "List of LLM responses<br/>(plain text)<br/>(dxGPT)",
        "Raw Differential Diagnosis<br/>(Extracted text block)<br/>(dxGPT)",
        "Differential Diagnosis ID<br/>(dxGPT)",
        "Rank Position<br/>(Integer)<br/>(dxGPT)",
        "Disease Name<br/>(String)<br/>(dxGPT)",
        "Reasoning<br/>(String)<br/>(dxGPT)",
        "1. inits configuration<br/>(Semantic Judge)",
        "model_id<br/>(Semantic Judge)",
        "prompt_id<br/>(Semantic Judge)",
        "case_bench_id<br/>(Semantic Judge)",
        "case_text<br/>(Semantic Judge)",
        "Case Model<br/>(Pydantic Schema)<br/>(Semantic Judge)",
        "(Judgment Cases Pydantic Schema)<br/>(Semantic Judge)",
        "List of Clinical Cases<br/>(Pydantic models)<br/>(Semantic Judge)",
        "List of Semantic Judgments<br/>(plain text)<br/>(Semantic Judge)",
        "List of Judgment Cases w/ Semantic Results<br/>(Pydantic Models)<br/>(Semantic Judge)",
        "Raw Semantic Judgment<br/>(JSON response)<br/>(Semantic Judge)",
        "differential_diagnosis_semantic_relationship_id<br/>(Integer)<br/>(Semantic Judge)",
        "cases_bench_id<br/>(Integer)<br/>(Semantic Judge)",
        "rank_id<br/>(Integer)<br/>(Semantic Judge)",
        "1. inits configuration<br/>(Severity Judge)",
        "model_id<br/>(Severity Judge)",
        "prompt_id<br/>(Severity Judge)",
        "case_bench_id<br/>(Severity Judge)",
        "case_text<br/>(Severity Judge)",
        "Case Model<br/>(Pydantic Schema)<br/>(Severity Judge)",
        "(Judgment Cases Pydantic Schema)<br/>(Severity Judge)",
        "List of Clinical Cases<br/>(Pydantic models)<br/>(Severity Judge)",
        "List of Severity Assessments<br/>(plain text)<br/>(Severity Judge)",
        "List of Judgment Cases w/ Severity Results<br/>(Pydantic Models)<br/>(Severity Judge)",
        "Raw Severity Assessment<br/>(JSON response)<br/>(Severity Judge)",
        "differential_diagnosis_severity_assessment_id<br/>(Integer)<br/>(Severity Judge)",
        "cases_bench_id<br/>(Integer)<br/>(Severity Judge)",
        "rank_id<br/>(Integer)<br/>(Severity Judge)",
    ]
    
    # Assign categories
    for node in app_components:
        categories[node] = "application_components"
    for node in core_functions:
        categories[node] = "core_functions"
    for node in framework_components:
        categories[node] = "framework_components"
    for node in database_tables:
        categories[node] = "database_tables"
    for node in database_functions:
        categories[node] = "database_functions"
    for node in selected_components:
        categories[node] = "selected_components"
    for node in command_arguments:
        categories[node] = "command_arguments"
    for node in data_flow_elements:
        categories[node] = "data_flow_elements"
    
    return categories

class UnifiedCompleteGraph(PredicateGraph):
    def __init__(self):
        super().__init__("unified_complete")
    
    def get_node_categories(self):
        """Return node category mapping for color assignment"""
        return get_node_categories()
    
    def get_color_map(self):
        """Return color mapping for different node categories"""
        return {
            "application_components": {"color": "#afa", "border": "#3a3"},
            "core_functions": {"color": "#7d7", "border": "#3a3"}, 
            "framework_components": {"color": "#bbf", "border": "#33f"},
            "database_tables": {"color": "#f9f", "border": "#333"},
            "database_functions": {"color": "#fbb", "border": "#d33"},
            "data_flow_elements": {"color": "#f9f9f9", "border": "#999"},
            "command_arguments": {"color": "#ffd", "border": "#aa3"},
            "selected_components": {"color": "#ffb", "border": "#b90"},
            "parser_components": {"color": "#fcf", "border": "#90b"},
        }
    
    def add_unified_complete_flow(self):
        """Add the unified complete flow using the improved triplets"""
        triplets = get_all_triplets()
        
        for source, predicate, target in triplets:
            self.add_edge(source, predicate, target)
    
    def generate_vis_js_file(self):
        """Generate a vis.js format file with nodes and edges data"""
        print("🎨 Generating vis.js file...")
        
        # Get all nodes from triplets
        all_nodes = set()
        for source, predicate, target in self.get_triplets():
            all_nodes.add(source)
            all_nodes.add(target)
        
        # Create nodes data with colors
        node_categories = self.get_node_categories()
        color_map = self.get_color_map()
        
        nodes_data = []
        node_to_id = {}
        
        for i, node in enumerate(sorted(all_nodes), 1):
            # Use string IDs like the original
            # Convert node name to safe ID format
            node_id = node.replace('<br/>', '_br_').replace('/', '_').replace(' ', '_').replace('(', '').replace(')', '').replace('.', '_').replace(',', '').replace('--', '_').replace('__', '_')
            
            node_to_id[node] = node_id
            
            category = node_categories.get(node, "data_flow_elements")
            color_info = color_map.get(category, {"color": "#f9f9f9", "border": "#999"})
            
            nodes_data.append({
                "id": node_id,
                "label": node.replace('<br/>', '\n'),  # Convert to newlines for vis.js
                "color": {
                    "background": color_info["color"],
                    "border": color_info["border"]
                },
                "shape": "box",
                "font": {
                    "size": 12,
                    "color": "#000"
                },
                "title": node.replace('<br/>', '<br/>') + f" ({category})",
                "size": self.get_node_size(category)
            })
        
        # Create edges data
        edges_data = []
        for i, (source, predicate, target) in enumerate(self.get_triplets(), 1):
            edges_data.append({
                "from": node_to_id[source],
                "to": node_to_id[target],
                "label": predicate,
                "arrows": "to",
                "font": {
                    "size": 10,
                    "color": "#333"
                },
                "color": {
                    "color": "#666"
                },
                "width": 2,
                "smooth": {
                    "type": "continuous"
                },
                "title": f"{source} {predicate} {target}"
            })
        
        # Generate JavaScript content
        vis_content = f"""// Unified Complete Architecture Visualization Data
// Generated by Graph29 Sequential Prompts Framework

var nodes = {json.dumps(nodes_data, indent=2)};
var edges = {json.dumps(edges_data, indent=2)};"""
        
        # Write to vis_output directory
        vis_output_dir = Path(__file__).parent / "vis_output"
        vis_output_dir.mkdir(exist_ok=True)
        
        vis_file = vis_output_dir / f"{self.module_name}_vis.js"
        with open(vis_file, 'w', encoding='utf-8') as f:
            f.write(vis_content)
        
        print(f"✅ Generated {vis_file}")
        print(f"📊 Statistics: {len(nodes_data)} nodes, {len(edges_data)} edges")
        print(f"📁 File size: {len(vis_content):,} bytes")
        
        return vis_file
    
    def get_node_size(self, category):
        """Return node size based on category"""
        size_map = {
            "core_functions": 30,
            "framework_components": 25,
            "database_tables": 25,
            "application_components": 20,
            "selected_components": 18,
            "command_arguments": 14,
            "data_flow_elements": 12,
            "database_functions": 15
        }
        return size_map.get(category, 12)

def main():
    """Main execution function"""
    print("🚀 Generating Unified Complete Architecture Visualization")
    print("=" * 60)
    
    # Create the graph
    graph = UnifiedCompleteGraph()
    
    # Add all the flows
    graph.add_unified_complete_flow()
    
    # Generate the vis.js file
    graph.generate_vis_js_file()
    
    print("=" * 60)
    print("🎉 Unified Complete Visualization Generation Complete!")

if __name__ == "__main__":
    main() 